{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c454417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_wine, load_digits, load_breast_cancer\n",
    "from mislabelling import symmetric_noise, pair_noise, NNAR\n",
    "from testing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bfe49ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOLUTION = 10\n",
    "TRIALS = 35\n",
    "N_ESTIMATORS = 10\n",
    "TEST_SIZE = 0.25\n",
    "ITERATIONS = 20\n",
    "\n",
    "noises = (symmetric_noise, pair_noise, pair_noise, pair_noise, NNAR)\n",
    "datasets = (load_wine(), load_digits(), load_breast_cancer(), load_gmm5())\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "accuracies_mean = []\n",
    "accuracies_se = []\n",
    "relabelling_f1_success = []\n",
    "relabelling_f1_se = []\n",
    "relabelling_acc_success = []\n",
    "relabelling_acc_se = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "176ac661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratio(data):\n",
    "    values, counts = np.unique(data.target, return_counts=True)\n",
    "    print({int(k): int(v) for k, v in zip(values, counts)})\n",
    "    total_vals = sum(counts)\n",
    "\n",
    "    noise_ratio = [1 - count/total_vals for count in counts]\n",
    "    noise_ratio /= min(noise_ratio)\n",
    "    print([float(f\"{val:.3g}\") for val in noise_ratio])\n",
    "    return noise_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53f51317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Experiments for Dataset 1\n",
      "Starting Experiments for Noise 5\n",
      "Starting Experiments for Dataset 2\n",
      "Starting Experiments for Noise 5\n",
      "Starting Experiments for Dataset 3\n",
      "Starting Experiments for Noise 5\n",
      "Starting Experiments for Dataset 4\n",
      "Starting Experiments for Noise 5\n"
     ]
    }
   ],
   "source": [
    "for data in datasets:\n",
    "    print(f\"Starting Experiments for Dataset {datasets.index(data) + 1}\")\n",
    "    for i in range(4,5):\n",
    "        print(f\"Starting Experiments for Noise {i + 1}\")\n",
    "        \n",
    "        unique_pairs = None\n",
    "        noise_ratio = None\n",
    "        clf = None\n",
    "\n",
    "        if i == 2:\n",
    "            noise_ratio = get_ratio(data)\n",
    "        if i == 3:\n",
    "            unique_pairs = True\n",
    "        if i == 4:\n",
    "            rf.fit(data.data, data.target)\n",
    "            clf = rf\n",
    "\n",
    "        accuracies_all, auc_all, relabelling_f1_all, relabelling_acc_all, x_axis = run_noise_level_experiment(\n",
    "        data, RandomForestClassifier, noises[i],\n",
    "        n_estimators=N_ESTIMATORS, trials=TRIALS,\n",
    "        resolution=RESOLUTION, test_size=TEST_SIZE, iterations=ITERATIONS,\n",
    "        noise_ratio=noise_ratio, clf=clf, unique_pairs = unique_pairs\n",
    "        )\n",
    "        accuracies_boot, auc_boot, relabelling_f1_boot, relabelling_acc_boot, x_axis = run_noise_level_experiment(\n",
    "        data, RandomForestClassifier, noises[i],\n",
    "        n_estimators=N_ESTIMATORS, trials=TRIALS,\n",
    "        resolution=RESOLUTION, test_size=TEST_SIZE, iterations=ITERATIONS,\n",
    "        control=False, bootstrapping=True,\n",
    "        noise_ratio=noise_ratio, clf=clf, unique_pairs = unique_pairs\n",
    "        )\n",
    "\n",
    "        accuracies_all = np.concatenate([accuracies_all, accuracies_boot[:1]], axis=0)\n",
    "        auc_all = np.concatenate([accuracies_all, auc_boot[:1]], axis=0)\n",
    "        relabelling_f1_all = np.concatenate([relabelling_f1_all, relabelling_f1_boot[:1]], axis=0)\n",
    "        relabelling_acc_all = np.concatenate([relabelling_acc_all, relabelling_acc_boot[:1]], axis=0)\n",
    "\n",
    "        # Process results\n",
    "        accuracies_mean_exp, accuracies_se_exp = process_experiment_result(accuracies_all)\n",
    "        relabelling_f1_success_exp, relabelling_f1_se_exp = process_experiment_result(relabelling_f1_all)\n",
    "        relabelling_acc_success_exp, relabelling_acc_se_exp = process_experiment_result(relabelling_acc_all)\n",
    "\n",
    "        accuracies_mean.append(accuracies_mean_exp)\n",
    "        accuracies_se.append(accuracies_se_exp)\n",
    "        relabelling_f1_success.append(relabelling_f1_success_exp)\n",
    "        relabelling_f1_se.append(relabelling_f1_se_exp)\n",
    "        relabelling_acc_success.append(relabelling_acc_success_exp)\n",
    "        relabelling_acc_se.append(relabelling_acc_se_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32dc7d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to experiment_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Stack your results into a single big DataFrame\n",
    "results = []\n",
    "\n",
    "# Loop through the results and create rows\n",
    "for dataset_idx, dataset_results in enumerate(zip(accuracies_mean, accuracies_se, relabelling_f1_success, relabelling_f1_se, relabelling_acc_success, relabelling_acc_se)):\n",
    "    for noise_idx, (acc_mean, acc_se, f1_mean, f1_se, acc_succ_mean, acc_succ_se) in enumerate(zip(*dataset_results)):\n",
    "        for res_idx, (am, ase, f1m, f1se, asm, asse) in enumerate(zip(acc_mean, acc_se, f1_mean, f1_se, acc_succ_mean, acc_succ_se)):\n",
    "            results.append({\n",
    "                'Dataset': dataset_idx,\n",
    "                'Noise Type': noise_idx,\n",
    "                'Noise Level Index': res_idx,\n",
    "                'Accuracy Mean': am,\n",
    "                'Accuracy SE': ase,\n",
    "                'Relabelling F1 Mean': f1m,\n",
    "                'Relabelling F1 SE': f1se,\n",
    "                'Relabelling Accuracy Mean': asm,\n",
    "                'Relabelling Accuracy SE': asse\n",
    "            })\n",
    "\n",
    "# Convert list of dicts into a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv(\"experiment_results_2.csv\", index=False)\n",
    "\n",
    "print(\"Saved results to experiment_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dissertation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
