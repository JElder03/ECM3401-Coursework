{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "\n",
    "from AdjustedRandomForest import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "Individual Accuracies: [0.8949494949494949, 0.8939393939393939, 0.9040404040404041, 0.9040404040404041, 0.9040404040404041, 0.907070707070707, 0.902020202020202, 0.8888888888888888, 0.901010101010101, 0.901010101010101]\n",
      "Average Accuracy: 0.9001010101010101\n",
      "\n",
      "Control\n",
      "Individual Accuracies: [0.9040404040404041, 0.896969696969697, 0.907070707070707, 0.896969696969697, 0.9030303030303031, 0.9030303030303031, 0.897979797979798, 0.906060606060606, 0.897979797979798, 0.8929292929292929]\n",
      "Average Accuracy: 0.9006060606060604\n"
     ]
    }
   ],
   "source": [
    "# CONTROL - NO MISLABELLING\n",
    "scores_my = []\n",
    "scores_std = []\n",
    "\n",
    "for _ in range(10):\n",
    "    X, y = make_classification(n_samples=3000, n_features=2, n_redundant=0, n_informative=2, n_clusters_per_class=1, n_classes=2,  random_state = 1, flip_y=0.0000001)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state = 1)\n",
    "    \n",
    "    rf, corrected_y = train(RandomForestClassifier, X_train, y_train, np.unique(y), 5)\n",
    "    y_test_pred = rf.predict(X_test)\n",
    "    scores_my.append(metrics.accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=5, criterion='entropy')\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_test_pred = rf.predict(X_test)\n",
    "    scores_std.append(metrics.accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "print(f\"Test\\nIndividual Accuracies: {scores_my}\\nAverage Accuracy: {np.mean(scores_my)}\\n\")\n",
    "print(f\"Control\\nIndividual Accuracies: {scores_std}\\nAverage Accuracy: {np.mean(scores_std)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1206\n",
      "458\n",
      "1206\n",
      "506\n",
      "1206\n",
      "501\n",
      "1206\n",
      "507\n",
      "1206\n",
      "483\n",
      "1206\n",
      "511\n",
      "1206\n",
      "488\n",
      "1206\n",
      "507\n",
      "1206\n",
      "495\n",
      "1206\n",
      "500\n",
      "Test\n",
      "Individual Accuracies: [0.5151515151515151, 0.49292929292929294, 0.4818181818181818, 0.4696969696969697, 0.4676767676767677, 0.5212121212121212, 0.4727272727272727, 0.494949494949495, 0.48787878787878786, 0.4636363636363636]\n",
      "Average Accuracy: 0.48676767676767685\n",
      "\n",
      "Control\n",
      "Individual Accuracies: [0.5040404040404041, 0.5373737373737374, 0.5, 0.4898989898989899, 0.501010101010101, 0.5080808080808081, 0.5080808080808081, 0.4676767676767677, 0.4868686868686869, 0.5222222222222223]\n",
      "Average Accuracy: 0.5025252525252525\n"
     ]
    }
   ],
   "source": [
    "# MISLABELLING\n",
    "scores_my = []\n",
    "scores_std = []\n",
    "N_CLASSES = 2\n",
    "MISLABELLING = 0.4\n",
    "\n",
    "for _ in range(10):\n",
    "    X, y = make_classification(n_samples=3000, n_features=2, n_redundant=0, n_informative=2, n_clusters_per_class=1, n_classes=N_CLASSES, flip_y=0.00000001)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "    \n",
    "    y_mislabelled = np.copy(y_train)\n",
    "\n",
    "    for i in range(int(len(y_mislabelled) * MISLABELLING)):\n",
    "        y_mislabelled[i] = (y_mislabelled[i] + random.randint(1, N_CLASSES - 1)) % N_CLASSES\n",
    "\n",
    "    print(sum(i==j for i, j in zip(y_mislabelled, y_train)))\n",
    "    np.random.shuffle(y_mislabelled)\n",
    "\n",
    "    rf, corrected_y = train(RandomForestClassifier, X_train, y_mislabelled, np.unique(y), 5)\n",
    "    y_test_pred = rf.predict(X_test)\n",
    "    print(sum(i==j for i, j in zip(y_test_pred, y_train)))\n",
    "    scores_my.append(metrics.accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=5, criterion='entropy')\n",
    "    rf.fit(X_train, y_mislabelled)\n",
    "    y_test_pred = rf.predict(X_test)\n",
    "    scores_std.append(metrics.accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "print(f\"Test\\nIndividual Accuracies: {scores_my}\\nAverage Accuracy: {np.mean(scores_my)}\\n\")\n",
    "print(f\"Control\\nIndividual Accuracies: {scores_std}\\nAverage Accuracy: {np.mean(scores_std)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
